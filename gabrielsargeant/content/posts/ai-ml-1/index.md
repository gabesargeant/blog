---
title: "My thoughts about the future of my work and how AI will impact me alone. Yes, that's correct I don't care about how it impacts other people. Let the world burn..."
date: 2023-02-15
draft: true
---

{{< note pos="right" txt="This is actually a how to guide on what I think is best practice with OpenAI at the moment. YMMV">}}

I was watching a Tom Scott video about AI, more precisely ChatGPT. [Linked Here](https://www.youtube.com/watch?v=jPhJbKBuNnA)  He was being his usual amazed self and both marveling and worrying about at how good it was at coding. So, the next day at work I started using OpenAI's chat bot to help out with work. It was kinda good. I'm not hating this future.

{{< note pos="left" txt="At the end of the video, Mr Scott remarks that he doesn't want AI trained on his video essays. I feel that Mr Scott is missing an  opportunity where he could catfish more views out of his audience as he wraps up his youtube career. *I maybe gone, but a facsimile of me remains, I feed it a copy of wired each week and it makes a video*. As all millennials know you gotta hustle for that passive income :D" >}}

After watching Tom Scott's video. My next workday started like this:

- 8:30 - Start describing a problem I have at work to ChatGPT and playing with the results in a Jupyter Notebook. 
- 10:00 - Amazed at the stacks of code the AI was generating I went for a coffee and espoused my amazement at just how good ChatGPT was. 
- 10:30 - Starting to shake out the main logic of the code I realize, nothing the AI has written comes close to touching the complexity of the problem I'm dealing with. 
- 11:00 - I'm writing code, but using Chat GPT in a different way. This is where things got really productive for me. 

It took me half a day of use to figure out that I'm going to be the one doing the software construction. At least until I either die, or rage quit. Computer's are not taking our jobs in that regard. However, If I were running Stack Overflow I'd be scared to death. 

At it's core, ChatGPT read the docs. It read all of them, it knows it all. **All of the docs**. When you ask it a question it gives you an expert answer. That's how it'll change work. Less fuck-ups. And over time more common code. 

{{< img src="rtfm.png" alt="ChatGPT read the fucking manual">}} 

What is fun to ponder is just how consistent in answers it will be. There's a million ways to describe a problem. I imagine asking Java questions to the AI will give you lots of answers in the many fad like flavors that have graced Java over the years. Something like golang maybe a bit consistent because it's a more centrally orthodox and opinionated language. 

AI will eventually own the boilerplate. And I'm happy to cede it this ground.

However, GitHub Co-pilot and other helper intellisense coding programs seem IMO less useful to me. I've always thought about the process of writing software as describing what the real problem is. Helper software like co-pilot give you boosts in snippets, but you still need to know where you're going and what you want to get done. It's the same with ChatGPT. It requires direction. 

The flow I found useful was asking for help with the tedious bits. A good example was doing some file system manipulation. It's not super hard, but I don't often do it. So I always go back to the docs to reread when I have to and I always feel like I'm taking too much time on the small stuff. This right here is 10-15 minutes of me stuffing about in the docs, down to 30 seconds where I type out what I need to do and AI hammers out a quick solution I can start with. I feel that this will be the most significant use of Chat GPT.





